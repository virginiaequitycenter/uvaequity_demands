Order =  c(7,
4,
3,
1,
5,
6,
2
)
)
demands_for_vis <-
demands_tags %>%
inner_join(demands_text) %>%
group_by(YEAR, Title, Code) %>%
summarize(n = n()) %>%
spread(Code, n, fill = 0) %>%
gather(Code, Count, -c(YEAR, Title)) %>%
left_join(details) %>%
arrange(YEAR, YearOrder, Title )
demographic_breakdown_prep <-
demands_for_vis %>%
filter(!Title  == "Diversity Recommendation Index_8_14_17.pdf") %>%
group_by(Code, Demographic) %>%
summarize(Count = sum(Count)) %>%
group_by(Code) %>%
mutate(Percent = round(Count/sum(Count)*100, 1))
demographic_breakdown <-
demographic_breakdown_prep %>%
group_by(Demographic) %>%
summarize(Count = sum(Count)) %>%
mutate(Percent = 10,
Code = "Legend",
Count = 0) %>%
bind_rows(
demographic_breakdown_prep %>%
group_by(Demographic) %>%
summarize(Count = sum(Count)) %>%
mutate(Percent = round(Count / sum(Count) * 100, 1),
Code = "Total")
)%>%
bind_rows(demographic_breakdown_prep) %>%
group_by(Code) %>%
inner_join(Demographic_Order) %>%
arrange(Order)
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(demographic_breakdown, path =  "data/demos.csv")
# create id for later investigation
demands_joined <-
demands_text %>%
inner_join(demands_tags)
demands_joined <- demands_joined %>%
mutate(text_id = paste0(demand_id, "-", DocTitle))
# 2. create corpus
dem_corpus <- corpus(demands_joined,
docid_field = "text_id",
text_field = "Text",
unique_docnames = FALSE)
# document-feature matrix
dem_dfm <- dfm(dem_corpus, tolower = TRUE,
remove = stopwords(), remove_punct = TRUE,
verbose = TRUE)
# 3. Generate list of most frequent words by theme and most distinctive words by theme
# generate frequency
dem_freq <- textstat_frequency(dem_dfm, n = 10, groups = "Code") %>%
as_tibble() %>%
mutate(chi2 = 0, source = "freq") %>%
select(code = group, feature, chi2, freq = frequency, source)
# generate keyness by groups
dem_code <- dfm(dem_dfm, groups = "Code")
# loop through groups (using chi2, could use pmi, lr, etc.)
dem_key <- data.frame()
for (g in docnames(dem_code)) {
df_temp <- head(textstat_keyness(dem_code, target = g), 10)
df_temp[["target"]] <- g
dem_key <- rbind(dem_key, df_temp)
}
dem_key <- dem_key %>%
as_tibble() %>%
mutate(source = "key") %>%
select(code = target, feature, chi2, freq = n_target, source)
# bind keyness and frequency
n = 2
blank_key <-
data.frame( code = rep(unique(dem_key$code), each = 2*n),
feature = c("", " "),
chi2 = 0,
freq = 0,
source = c("key", "freq")
)
keyfreq <- rbind(dem_key, dem_freq, blank_key) %>%
group_by(code,source ) %>%
# arrange(chi2, desc(freq)) %>%
mutate(
#freq = if_else(source == "freq", -1*freq, freq),
order = row_number(),
max_freq = max(freq),
freq = round((freq/max_freq)*100)) %>%
ungroup() %>%
mutate(code_feature = paste0(code,feature)) %>%
arrange(source, code, desc(freq)) %>%
mutate(code = case_when(
code == "Minority Faculty / Staff Recruitment and Retention" ~ "Minority Factuly/Staff",
code == "Current Initiatives and Working Groups" ~ "Current Initiatives",
TRUE ~ code
))
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(keyfreq, path =  "data/keyness.csv")
timeline_events <-
events %>%
mutate(
Day = as.numeric(Day),
Month = case_when(
is.na(Month) ~ 1,
TRUE ~ Month
),
Day = case_when(
is.na(Day) ~ 1,
TRUE ~ Day
),
Percent = ((Month - 1)*31 + (Day - 1 ))/(12*31),
YearPercent = Year + Percent
) %>%
rowwise() %>%
mutate(vert = runif(1,0, 1))
timeline_events[1, "vert"] <- 0
timeline_events[2, "vert"] <- 1.2
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(timeline_events, path =  "data/events.csv")
# Images for Timeline -----------------------------------------------------
setwd("/Users/samuelpowers/Box Sync/VisualizingDemands")
images <- read_csv("./data/practice_timeline_images.csv")
timeline_images <-
images %>%
mutate(
Day = as.numeric(Day),
Month = as.numeric(Month),
Month = case_when(
is.na(Month) ~ 1,
TRUE ~ Month
),
Day = case_when(
is.na(Day) ~ 1,
TRUE ~ Day
),
Percent = ((Month - 1)*31 + (Day - 1 ))/(12*31),
YearPercent = Year + Percent
) %>%
rowwise() # %>%
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(timeline_images, path =  "data/images.csv")
shades %>%
filter(brand == "fe") %>%
select(hex) %>%
mutate(hex = paste0("#", hex)) %>%
pull()
palette_in <- c("#fde7da", "#f2d3b1", "#efd1b7", "#e8bfa3", "#e2ad85", "#dfad89", "#dca77d", "#dcb17d", "#d39156", "#ac7752", "#bd7b45", "#a86b3f","#9d5d2d", "#894f29", "#824f30",  "#7d452c", "#6d3b20", "#683a20")
palette_out <- sample(palette_in, length(palette_in))
pal_use <- NULL
for (pal in palette_out)  {
pal_use <- paste0(pal_use, pal, sep = "', '")
}
pal_use
keyfreq <- rbind(dem_key, dem_freq, blank_key) %>%
group_by(code,source ) %>%
# arrange(chi2, desc(freq)) %>%
mutate(
#freq = if_else(source == "freq", -1*freq, freq),
order = row_number(),
count = freq,
max_freq = max(freq),
freq = round((freq/max_freq)*100)) %>%
ungroup() %>%
mutate(code_feature = paste0(code,feature)) %>%
arrange(source, code, desc(freq)) %>%
mutate(code = case_when(
code == "Minority Faculty / Staff Recruitment and Retention" ~ "Minority Factuly/Staff",
code == "Current Initiatives and Working Groups" ~ "Current Initiatives",
TRUE ~ code
))
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(keyfreq, path =  "data/keyness.csv")
keyfreq <- rbind(dem_key, dem_freq, blank_key) %>%
group_by(code,source ) %>%
# arrange(chi2, desc(freq)) %>%
mutate(
#freq = if_else(source == "freq", -1*freq, freq),
order = row_number(),
count = freq,
max_freq = max(freq),
freq = round((freq/max_freq)*100),
feature = str_to_sentence(feature)
) %>%
ungroup() %>%
mutate(code_feature = paste0(code,feature)) %>%
arrange(source, code, desc(freq)) %>%
mutate(code = case_when(
code == "Minority Faculty / Staff Recruitment and Retention" ~ "Minority Factuly/Staff",
code == "Current Initiatives and Working Groups" ~ "Current Initiatives",
TRUE ~ code
))
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(keyfreq, path =  "data/keyness.csv")
### Create sample dataset for this ###
n = 5000
df <- data.frame(
Outcome = sample(c(0,1), n, replace = TRUE),
Region = sample( c("North", "South", "East", "West"), n, replace = TRUE),
Covariate = sample(c("On", "Off"), n, replace = TRUE),
Year = sample( c(2012, 2013, 2014, 2015), n, replace = TRUE)
)
graph_data <-
df %>%
group_by(Year, Covariate, Region ) %>%
add_count() %>%
group_by(Year, Covariate, Region, n) %>%
summarize(percent = round(mean(Outcome)*100,2), count = sum(Outcome)) %>%
mutate(display = paste0(round(percent), "%") )
p <-
ggplot( graph_data, aes(x = Year, y = percent, color = Covariate )) +
geom_line(stat = "identity", alpha = .8 , size = 2) +
geom_point(stat = "identity", alpha = .8, size = 2) +
geom_text(data = graph_data %>%
group_by( Region, Covariate) %>%
arrange(desc(Year)) %>%
slice(1) ,
aes(x = Year + .05, label = display), color = "Black", alpha = 1, hjust = 0, size = 3) +
geom_text(data = graph_data %>%
group_by( Region, Covariate) %>%
arrange(Year) %>%
slice(1) ,
aes(x = Year - .05, label = display),hjust = 1, color = "Black", alpha = 1, hjust = 0, size = 3) +
geom_text(data = graph_data %>%
group_by( Region, Covariate,  Year) %>%
arrange(Region, Year, Covariate) %>%
select(-percent, -count, -display) %>%
spread(Covariate, n),
aes(x = Year, y = 0, label = paste0("(n = ", Off, " | ", On, ")")), vjust = 1.75, hjust  = .5, color = "Black",        alpha = 1, hjust = 0, size = 3)  +
facet_wrap(~Region,  strip.position = "top") +
scale_y_continuous(labels = function(x) paste0(round(x), "%"), expand = c(0, 0 ), limits = c(0, 60), breaks=seq(5,55, 5)) +
scale_x_continuous( breaks=seq(2012,2015, 1), limits = c(2011.75, 2015.25) )  +
coord_cartesian(clip = 'off') +
theme(panel.spacing = unit(2, "lines")) +
labs(x="Year", y="People, %", fill = "Covariate")  +
coord_cartesian(clip = 'off') +                       ##### This is incredibly Important. It lets you move graph values (the n values) below the x-axis
scale_fill_brewer(palette="Set1") +
ggtitle("Title Here") +
theme(
plot.title = element_text( face="bold", hjust = 0.5 ),
legend.title = element_text(),
legend.position = "top",
#    axis.title.x = element_text(vjust=-2),
#    axis.title.y = element_text(vjust= 2),
axis.text.x=element_text(vjust=-3),
#
axis.ticks.x = element_blank(),
panel.background =  element_rect(fill = "white", color = "black"),
panel.grid = element_blank(),
axis.line =  element_line(color  = "black")
)
p
graph_data <-
df %>%
group_by(Year, Covariate, Region ) %>%
add_count() %>%
group_by(Year, Covariate, Region, n) %>%
summarize(percent = round(mean(Outcome)*100,2), count = sum(Outcome)) %>%
mutate(display = paste0(round(percent), "% (", count, ")") )
p <-
ggplot( graph_data, aes(x = Year, y = percent, color = Covariate )) +
geom_line(stat = "identity", alpha = .8 , size = 2) +
geom_point(stat = "identity", alpha = .8, size = 2) +
geom_text(data = graph_data %>%
group_by( Region, Covariate) %>%
arrange(desc(Year)) %>%
slice(1) ,
aes(x = Year + .05, label = display), color = "Black", alpha = 1, hjust = 0, size = 3) +
geom_text(data = graph_data %>%
group_by( Region, Covariate) %>%
arrange(Year) %>%
slice(1) ,
aes(x = Year - .05, label = display),hjust = 1, color = "Black", alpha = 1, hjust = 0, size = 3) +
geom_text(data = graph_data %>%
group_by( Region, Covariate,  Year) %>%
arrange(Region, Year, Covariate) %>%
select(-percent, -count, -display) %>%
spread(Covariate, n),
aes(x = Year, y = 0, label = paste0("(n = ", Off, " | ", On, ")")), vjust = 1.75, hjust  = .5, color = "Black",        alpha = 1, hjust = 0, size = 3)  +
facet_wrap(~Region,  strip.position = "top") +
scale_y_continuous(labels = function(x) paste0(round(x), "%"), expand = c(0, 0 ), limits = c(0, 60), breaks=seq(5,55, 5)) +
scale_x_continuous( breaks=seq(2012,2015, 1), limits = c(2011.75, 2015.25) )  +
coord_cartesian(clip = 'off') +
theme(panel.spacing = unit(2, "lines")) +
labs(x="Year", y="People, %", fill = "Covariate")  +
coord_cartesian(clip = 'off') +                       ##### This is incredibly Important. It lets you move graph values (the n values) below the x-axis
scale_fill_brewer(palette="Set1") +
ggtitle("Title Here") +
theme(
plot.title = element_text( face="bold", hjust = 0.5 ),
legend.title = element_text(),
legend.position = "top",
#    axis.title.x = element_text(vjust=-2),
#    axis.title.y = element_text(vjust= 2),
axis.text.x=element_text(vjust=-3),
#
axis.ticks.x = element_blank(),
panel.background =  element_rect(fill = "white", color = "black"),
panel.grid = element_blank(),
axis.line =  element_line(color  = "black")
)
p
shades %>%
filter(brand == "fe") %>%
select(hex) %>%
mutate(hex = paste0("#", hex)) %>%
pull()
the_shades <-
shades %>%
filter(brand == "fe") %>%
select(hex) %>%
mutate(hex = paste0("#", hex)) %>%
pull()
the_shades
sample(the_shades, 13)
pallete_out <- sample(the_shades, 13)
pallete_out <- sample(the_shades, 14)
pallete_out
pal_use <- NULL
for (pal in palette_out)  {
pal_use <- paste0(pal_use, pal, sep = "', '")
}
pal_use
keyfreq <- rbind(dem_key, dem_freq, blank_key) %>%
group_by(code,source ) %>%
# arrange(chi2, desc(freq)) %>%
mutate(
#freq = if_else(source == "freq", -1*freq, freq),
order = row_number(),
count = freq,
max_freq = max(freq),
freq = round((freq/max_freq)*100),
feature = str_to_sentence(feature)
) %>%
ungroup() %>%
mutate(code_feature = paste0(code,feature)) %>%
arrange(source, code, desc(freq)) %>%
mutate(
code_color = code,
code = case_when(
code == "Minority Faculty / Staff Recruitment and Retention" ~ "Minority Factuly/Staff",
code == "Current Initiatives and Working Groups" ~ "Current Initiatives",
TRUE ~ code
))
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(keyfreq, path =  "data/keyness.csv")
the_shades <-
shades %>%
filter(brand == "fe") %>%
select(hex) %>%
mutate(hex = paste0("#", hex)) %>%
pull()
pallete_out <- sample(the_shades, 14)
pal_use <- NULL
for (pal in palette_out)  {
pal_use <- paste0(pal_use, pal, sep = "', '")
}
pal_use
the_shades <-
shades %>%
filter(brand == "fe") %>%
select(hex) %>%
mutate(hex = paste0("#", hex)) %>%
pull()
pallete_out <- sample(the_shades, 14)
pal_use <- NULL
for (pal in palette_out)  {
pal_use <- paste0(pal_use, pal, sep = "', '")
}
pal_use
the_shades
pallete_out <- sample(the_shades, 25)
pallete_out
pal_use <- NULL
for (pal in palette_out)  {
pal_use <- paste0(pal_use, pal, sep = "', '")
}
pal_use
# Images for Timeline -----------------------------------------------------
setwd("/Users/samuelpowers/Box Sync/VisualizingDemands")
images <- read_csv("./data/practice_timeline_images.csv")
timeline_images <-
images %>%
mutate(
Day = as.numeric(Day),
Month = as.numeric(Month),
Month = case_when(
is.na(Month) ~ 1,
TRUE ~ Month
),
Day = case_when(
is.na(Day) ~ 1,
TRUE ~ Day
),
Percent = ((Month - 1)*31 + (Day - 1 ))/(12*31),
YearPercent = Year + Percent
) %>%
rowwise() # %>%
timeline_images
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(timeline_images, path =  "data/images.csv")
# Images for Timeline -----------------------------------------------------
setwd("/Users/samuelpowers/Box Sync/VisualizingDemands")
images <- read_csv("./data/practice_timeline_images.csv")
timeline_images <-
images %>%
mutate(
Day = as.numeric(Day),
Month = as.numeric(Month),
Month = case_when(
is.na(Month) ~ 1,
TRUE ~ Month
),
Day = case_when(
is.na(Day) ~ 1,
TRUE ~ Day
),
Percent = ((Month - 1)*31 + (Day - 1 ))/(12*31),
YearPercent = Year + Percent
) %>%
rowwise() # %>%
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(timeline_images, path =  "data/images.csv")
dem_key <- dem_key %>%
as_tibble() %>%
mutate(source = "key") %>%
select(code = target, feature, chi2, freq = n_target, source)
# 3. Generate list of most frequent words by theme and most distinctive words by theme
# generate frequency
dem_freq <- textstat_frequency(dem_dfm, n = 10, groups = "Code") %>%
as_tibble() %>%
mutate(chi2 = 0, source = "freq") %>%
select(code = group, feature, chi2, freq = frequency, source)
# generate keyness by groups
dem_code <- dfm(dem_dfm, groups = "Code")
# loop through groups (using chi2, could use pmi, lr, etc.)
dem_key <- data.frame()
for (g in docnames(dem_code)) {
df_temp <- head(textstat_keyness(dem_code, target = g), 10)
df_temp[["target"]] <- g
dem_key <- rbind(dem_key, df_temp)
}
dem_key <- dem_key %>%
as_tibble() %>%
mutate(source = "key") %>%
select(code = target, feature, chi2, freq = n_target, source)
dem_key
demands_for_vis <-
demands_tags %>%
inner_join(demands_text) %>%
group_by(YEAR, Title, Code) %>%
summarize(n = n()) %>%
spread(Code, n, fill = 0) %>%
gather(Code, Count, -c(YEAR, Title)) %>%
left_join(details) %>%
arrange(YEAR, YearOrder, Title )
demographic_breakdown_prep <-
demands_for_vis %>%
filter(!Title  == "Diversity Recommendation Index_8_14_17.pdf") %>%
group_by(Code, Demographic) %>%
summarize(Count = sum(Count)) %>%
group_by(Code) %>%
mutate(Percent = round(Count/sum(Count)*100, 1))
demographic_breakdown <-
demographic_breakdown_prep %>%
group_by(Demographic) %>%
summarize(Count = sum(Count)) %>%
mutate(Percent = 10,
Code = " ",
Count = 0) %>%
bind_rows(
demographic_breakdown_prep %>%
group_by(Demographic) %>%
summarize(Count = sum(Count)) %>%
mutate(Percent = round(Count / sum(Count) * 100, 1),
Code = "Total")
)%>%
bind_rows(demographic_breakdown_prep) %>%
group_by(Code) %>%
inner_join(Demographic_Order) %>%
arrange(Order)
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(demographic_breakdown, path =  "data/demos.csv")
demographic_breakdown <-
demographic_breakdown_prep %>%
group_by(Demographic) %>%
summarize(Count = sum(Count)) %>%
mutate(Percent = 10,
Code = "Key",
Count = 0) %>%
bind_rows(
demographic_breakdown_prep %>%
group_by(Demographic) %>%
summarize(Count = sum(Count)) %>%
mutate(Percent = round(Count / sum(Count) * 100, 1),
Code = "Total")
)%>%
bind_rows(demographic_breakdown_prep) %>%
group_by(Code) %>%
inner_join(Demographic_Order) %>%
arrange(Order)
setwd("/Volumes/GoogleDrive/My Drive/Equity Center/SamsGithub/uvaequity_demands/assets/")
write_csv(demographic_breakdown, path =  "data/demos.csv")
install.packages("spacyr")
library(spacyr)
